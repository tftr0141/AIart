{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tftr0141/AIart/blob/main/voicerecognition/VCW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VCW: Voice-Cut with Whisper\n",
        "openai-whisperをベースにしたボイスカットツールです。<br>\n",
        "音声を文章毎に切り分ける作業を自動化できます。<br>"
      ],
      "metadata": {
        "id": "EyFEYcPd44cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 環境の確認\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y5KURKKDDgaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QgbQn0kl4zrS"
      },
      "outputs": [],
      "source": [
        "#@title ライブラリのインストール\n",
        "!pip install pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import datetime\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google Driveへのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ilPl26wj5lRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 音声ファイルかフォルダを指定\n",
        "#@markdown フォルダを指定した場合、複数の音声ファイルを一括で処理します。\n",
        "audio_path = \"/content/drive/MyDrive/\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### テキストファイルを出力するか\n",
        "#@markdown チェックを入れた場合、音声を文章ごとに文字起こしして出力します。\n",
        "output_txt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### ログを出力するか\n",
        "#@markdown ログにはセリフの開始時間と終了時間が記載されます\n",
        "output_log = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### モデルサイズ\n",
        "#@markdown 大きいほうが正確ですが、時間がかかります。\n",
        "model_size = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"] {allow-input: false}\n",
        "\n",
        "audio_path_list = []\n",
        "if os.path.isdir(audio_path):\n",
        "  audio_path_list = glob.glob(os.path.join(audio_path, \"*\"))\n",
        "else:\n",
        "  audio_path_list.append(audio_path)\n",
        "audio_path_list.sort()\n",
        "print(\"ボイスカットする音声ファイル一覧：\")\n",
        "for audio in audio_path_list:\n",
        "  print(audio)\n",
        "\n",
        "print(\"\\nモデルの準備中…\")\n",
        "model = whisper.load_model(model_size)\n",
        "print(\"完了！\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ebp6I-sy68Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ボイスカット処理\n",
        "dt_now = datetime.datetime.now()\n",
        "output_dir_parent = dt_now.strftime('/content/drive/MyDrive/VCW-output/%Y-%m-%d-%H-%M-%S')\n",
        "os.makedirs(output_dir_parent, exist_ok=True)\n",
        "\n",
        "print(\"ファイルの出力先：\" + output_dir_parent)\n",
        "\n",
        "for i, path in enumerate(audio_path_list):\n",
        "  output_dir_child = os.path.splitext(os.path.basename(path))[0]\n",
        "  output_dir = os.path.join(output_dir_parent, output_dir_child)\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "  print(\"[\"+str(i+1)+\"/\"+str(len(audio_path_list))+\"]\")\n",
        "  result = model.transcribe(audio=path, verbose=False, language='Japanese')\n",
        "\n",
        "  audio = AudioSegment.from_file(path)\n",
        "  log = \"\"\n",
        "  print(\"文章数：\"+str(len(result['segments'])))\n",
        "  for j, segment in tqdm(enumerate(result['segments'])):\n",
        "    start = int(float(segment['start']))\n",
        "    end = int(float(segment['end']))\n",
        "    text = segment['text']\n",
        "\n",
        "    start_m, start_s = divmod(start, 60)\n",
        "    start_h, start_m = divmod(start_m, 60)\n",
        "    start_h_m_s = f'start: {str(start_h).zfill(2)}:{str(start_m).zfill(2)}:{str(start_s).zfill(2)}'\n",
        "    end_m, end_s = divmod(end, 60)\n",
        "    end_h, end_m = divmod(end_m, 60)\n",
        "    end_h_m_s = f'end: {str(end_h).zfill(2)}:{str(end_m).zfill(2)}:{str(end_s).zfill(2)}'\n",
        "\n",
        "    log += '[' + str(j).zfill(5) + ' ' + start_h_m_s + ' ' + end_h_m_s + f'] {text}\\n'\n",
        "\n",
        "    cropped_audio = audio[start*1000:end*1000]\n",
        "    cropped_audio.export(os.path.join(output_dir, str(j).zfill(5) + '.mp3'))\n",
        "\n",
        "    if output_txt:\n",
        "      with open(os.path.join(output_dir, str(j).zfill(5) + '.txt'), 'w') as f:\n",
        "        f.write(segment['text'])\n",
        "  \n",
        "  if output_log:\n",
        "    log_path = os.path.join(output_dir_parent, 'log_' + output_dir_child + '.txt')\n",
        "    with open(log_path, 'w') as f:\n",
        "      f.write(log)\n",
        "\n",
        "print('\\nEnjoy.')"
      ],
      "metadata": {
        "id": "MlkR1EA_8jXq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}